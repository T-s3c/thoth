#!/usr/bin/env python3

from lxml import etree
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.firefox.options import Options as FirefoxOptions
from selenium.webdriver.firefox.service import Service
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains
import os
import random
import string
import sys
import time

# check amount of passed arguments
if (len(sys.argv) != 2):
    print("usage: {} domain".format(sys.argv[0]))
    print("Visit spyonweb.com and extract reverse nameserver and ip address lookups")
    sys.exit(1)

options = FirefoxOptions()

# headless mode
options.add_argument("--headless")

# certificate errors
options.add_argument("--ignore-ssl-errors=yes")
options.add_argument('--ignore-certificate-errors')

# user agent
options.set_preference("general.useragent.override", "Safari: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/605.1.3 (KHTML, like Gecko) Version/11.1 Safari/605.1.3")

# prevent creation of geckodriver.log
service = Service(log_output="/dev/null", executable_path="/usr/local/bin/geckodriver")
driver = webdriver.Firefox(options=options, service=service)

# 10 seconds timeout
driver.set_page_load_timeout(15)

# 10 seconds default wait for element to be clickable
driver.implicitly_wait(15)

# browse spyonweb
rootdomain = sys.argv[1]

url = "https://spyonweb.com/" + rootdomain
driver.get(url)

# scroll to bottom
time.sleep(4)
actions = ActionChains(driver)
actions.send_keys(Keys.END).perform()
time.sleep(4)

sourceCode = driver.page_source
tree = etree.HTML(sourceCode)

# used to print the results
printElements = []

for element in tree.iterdescendants():
    # print headlines
    if (element.tag == "b"):
        if (element.text is not None):
            content = element.text.strip()
            if (rootdomain in content):
                continue
            elif ("Domain name:" in content):
                continue
            else:
                uniqElementsToPrint = sorted(set(printElements))
            
                print("\n########## " + content)
                # print all uniq elements
                for uniq in uniqElementsToPrint:
                    print(uniq)

    # stop printing output when nameserver section reached
    elif (element.tag == "h3"):
        if (element.text is not None):
            content = element.text.strip()
            if ("DNS Servers" in content):
                break
    
    # print all domains
    elif element.tag == "a" and "href" in element.attrib:
        href = element.get("href")
        # skip spyonweb, whois and alexa
        if ("spyonweb.com" in href or "/whois/" in href or "/alexa/" in href):
            continue
        else:
            href = href.replace("/go/","")
            href = href.replace("/","")
            printElements.append(href)

# get all nameserver
letters = string.ascii_lowercase
randStr = ""

for l in range(8):
    randStr = randStr + random.choice(letters)

tempFile = "/tmp/spyonweb-nameserver-lookup-" + randStr
os.system("dig +short NS " + rootdomain + " > " + tempFile)

# reverse lookup for each nameserver
with open(tempFile) as fp:
    for nameserver in fp:
        nameserver = nameserver.replace("\n","")
        nameserver = nameserver[:-1]

        url = "https://spyonweb.com/dns/" + nameserver
        driver.get(url)
        
        # scroll to bottom
        time.sleep(4)
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(4)
        
        sourceCode = driver.page_source
        tree = etree.HTML(sourceCode)
        
        # used to print the results
        printElements = []
        
        for element in tree.iterdescendants():
            # print headlines
            if (element.tag == "b"):
                if (element.text is not None):
                    content = element.text.strip()
                    if (not rootdomain in content):
                        uniqElementsToPrint = sorted(set(printElements))
                    
                        if (nameserver in content):
                            print("\n########## " + content, end="")
                        else:
                            print(" - " + content)
        
                        # print all uniq elements
                        for uniq in uniqElementsToPrint:
                            print(uniq)
        
            # print all domains
            elif element.tag == "a" and "href" in element.attrib:
                href = element.get("href")
                # skip spyonweb, whois and alexa
                if ("spyonweb.com" in href or "/whois/" in href or "/alexa/" in href):
                    continue
                else:
                    href = href.replace("/go/","")
                    href = href.replace("/","")
                    printElements.append(href)

driver.close()
os.remove(tempFile)

