#!/usr/bin/env python3

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.firefox.options import Options as FirefoxOptions
from selenium.webdriver.firefox.service import Service
import sys
import time
from urllib.parse import unquote

# check amount of passed arguments
if (len(sys.argv) != 2):
    print("usage: {} domain".format(sys.argv[0]))
    print("Visit www.zoomeye.org and extract rootdomains from company lookup")
    sys.exit(1)

options = FirefoxOptions()

# headless mode
options.add_argument("--headless")

# certificate errors
options.add_argument("--ignore-ssl-errors=yes")
options.add_argument('--ignore-certificate-errors')

# user agent
options.set_preference("general.useragent.override", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36")

# prevent creation of geckodriver.log
service = Service(log_output="/dev/null")
driver = webdriver.Firefox(options=options, service=service)

# seconds timeout
driver.set_page_load_timeout(60)

# seconds default wait for element to be clickable
driver.implicitly_wait(60)

# browse zoomeye
rootdomain = sys.argv[1]

url = "https://www.zoomeye.org/searchResult?q=" + rootdomain
driver.get(url)

# wait for page to load results
time.sleep(5)

rHosts = driver.find_elements(By.CLASS_NAME, "rdns")

allDomains = []

for h in rHosts:
    allDomains.append(h.text)

hrefs = driver.find_elements(By.CLASS_NAME, "search-result-real-site")

for e in hrefs:
    href = unquote(e.get_attribute("href"))
    clean = href.replace("https://","")
    c = clean.replace("http://","")
    allDomains.append(c.replace("/",""))

uniqDomains = sorted(set(allDomains))

for u in uniqDomains:
    print(u)

driver.close()

